---
title: "Test DEV"
format: 
  dashboard:
    scrolling: false
    nav-buttons: 
     - icon: github
       href: https://github.com/YCGS-lab/SPARK
     - icon: globe
       href: https://geospatial.yale.edu/
server: shiny
---
```{r}
#| label: setup
# Load packages and functions
library(shiny)
library(shinyvalidate)
library(quarto)
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
library(lubridate)
library(openair)
library(plotly)
library(zoo)
library(pracma)
library(bslib)
library(cowplot)
source("functions_for_app_dev.R")
```

# Tab 1

## {.sidebar width="300px"}
:::{.card}
Welcome to the Source Prediction of Aerosol using Residual Potassium (SPARK) tool! Intro the tool here

Before uploading your data, please ensure that it is formatted properly, as this SPARK tool expects specific columns in your CSV file. See the template to the right for an example on how to format your data. Once you're ready to check your data for formatting, click the "Browse..." button in the sidebar to upload your file for inspection.
:::

```{r}
# Prompt user to choose timestamp format
selectInput(
  inputId = "timestamp_string",
  label = "Timestamp Format",
  choices = c("%Y-%m-%dT%H:%M:%SZ",
              "%m/%d/%Y %H:%M",
              "%m/%d/%Y %H:%M:%S"),
  selected = "%Y-%m-%dT%H:%M:%SZ"
) 

# Prompt user to upload CSV for inspection
fileInput("file0", "Upload your CSV file for inspection here:", accept = ".csv")
```

```{r}
# Output inspection results
textOutput("inspection_results")
```

## Main Body

### Row {.tabset height=60%}
```{r}
#| title: Template
# Create template as an example
template <- data.frame("ID" = 1:5,
                       "latitude" = rep("#", 5),
                       "longitude" = rep("#", 5),
                       "value_datetime" = rep("see 'Column Explanation'", 5),
                       "timezone" = rep("see 'Column Explanation'", 5),
                       "station_ID" = rep("name of station", 5),
                       "value_OA" = rep("#", 5),
                       "value_K" = rep("#", 5),
                       "value_Fe" = rep("#", 5),
                       "value_Ca" = rep("#", 5),
                       "value_Ti" = rep("#", 5),
                       "value_Cl" = rep("#", 5),
                       "value_Sr" = rep("#", 5),
                       "uncertainty_OA" = rep("#", 5),
                       "uncertainty_K" = rep("#", 5),
                       "uncertainty_Fe" = rep("#", 5),
                       "uncertainty_Ca" = rep("#", 5),
                       "uncertainty_Ti" = rep("#", 5)
                       )

# Show template as table
knitr::kable(template)
```

::: {.card title="Column Explanation"}
- `ID`: (numeric) Identifier column with positive integers. `NA` values not allowed.

- `latitude`: (numeric) Latitude in decimal degrees between -180 and 180. `NA` values not allowed.

- `longitude`: (numeric) Longitude in decimal degrees between -180 and 180. `NA` values not allowed.

- `value_datetime`: (character) Date-time format of your data. `NA` values not allowed. Must be able to be parsed by using one of the following formats:
  - %m/%d/%Y %H:%M:%S
  - %m/%d/%Y %H:%M
  - %Y-%m-%dT%H:%M:%SZ
  
- `timezone`: (character) Time zone of your data. Must be either UTC or a different standard time, represented by Etc/GMT+X. Note that the POSIX notation for time zone is inverted (i.e., Etc/GMT+5 is UTC-5). `NA` values not allowed.

- `stationID`: (character or numeric) Station name or identifier, `NA` values not allowed.

- `value_OA`: (numeric) OA concentration in $\mu g / m^{3}$. `NA` values allowed.

- `value_K`: (numeric) K concentration in $ng / m^{3}$. `NA` values allowed.

- `value_Fe`: (numeric) Fe concentration in $ng / m^{3}$. `NA` values allowed.

- `value_Ca`: (numeric) Ca concentration in $ng / m^{3}$. `NA` values allowed.

- `value_Ti`: (numeric) Ti concentration in $ng / m^{3}$. `NA` values allowed.

- `value_Cl`: (numeric) Cl concentration in $ng / m^{3}$. `NA` values allowed.

- `value_Sr`: (numeric) Sr concentration in $ng / m^{3}$. `NA` values allowed.

- `uncertainty_OA`: (numeric) OA uncertainty in $\mu g / m^{3}$. `NA` values allowed.

- `uncertainty_K`: (numeric) K uncertainty in $ng / m^{3}$. `NA` values allowed.

- `uncertainty_Fe`: (numeric) Fe uncertainty in $ng / m^{3}$. `NA` values allowed.

- `uncertainty_Ca`: (numeric) Ca uncertainty in $ng / m^{3}$. `NA` values allowed.

- `uncertainty_Ti`: (numeric) Ti uncertainty in $ng / m^{3}$. `NA` values allowed.

:::

### Row {height=40%}
```{r}
#| title: Preview
# Output preview table if inspection passes
tableOutput("preview_table")
```

```{r}
#| context: server

# Check uploaded file
inspect_file <- reactive({
  # Return nothing if no file is uploaded
  if (is.null(input$file0)) {
    return(NULL)
  }
  
  # Otherwise, read in file
  data_for_checking <- utils::read.csv(input$file0$datapath)
  
  # Check data for formatting
  tryCatch({result <- check_data(data = data_for_checking,
                                 timestamp_format = input$timestamp_string)},
           error = function(e){
             return(e$message)
           })
})


# Generate preview if file passes inspection
create_preview <- reactive({
  # Return nothing if no file is uploaded
  if (is.null(input$file0)) {
    return(NULL)
  }
  
  # If inspection passes, read in uploaded file
  if (inspect_file() == "Success! Your data is formatted properly."){
    data_for_preview <- utils::read.csv(input$file0$datapath)
    
    # Comment this out because we're not using local_time anymore
    # for (i in 1:nrow(data_for_preview)){
    #   # Format value_datetime column according to the time zone and selected timestamp
    #   data_for_preview$value_datetime[i] <- as.character(as.POSIXct(data_for_preview$value_datetime[i],
    #                                     tz = data_for_preview$timezone[i],
    #                                     format = input$timestamp_string))
    # 
    #   data_for_preview$local_time[i] <- as.character(with_tz(data_for_preview$value_datetime[i], tzone = "America/New_York"))
    # }
    
    # Create an empty list to hold results
    df_list <- list()
    # For each unique timezone...
    for (a_timezone in unique(data_for_preview$timezone)){
      sub_df <- data_for_preview %>%
        # Filter to the rows with that timezone
        filter(timezone == a_timezone) %>%
        # Format value_datetime column according to the time zone and selected timestamp
        mutate(value_datetime = as.character(as.POSIXct(value_datetime, tz = a_timezone, format = input$timestamp_string))) 
      
      # Save result
      df_list[[a_timezone]] <- sub_df
    }
    
    data_for_preview_formatted <- df_list %>%
      # Combine results altogether
      purrr::list_rbind(x = .)
    
    return(data_for_preview_formatted)
  } 
})

# Render results of the inspection
output$inspection_results <- renderText({
  # Require a file to be uploaded
  shiny::validate(
    need(input$file0, "Result will be shown here after CSV is uploaded:")
  )
  
  # Perform inspection
  inspect_file()
})

# Render preview table if file passes inspection
output$preview_table <- renderTable({
  # Require a file to be uploaded
  shiny::validate(
    need(input$file0, "Preview will be shown here after CSV is uploaded:")
  )
  
  if (inspect_file() == "Success! Your data is formatted properly."){
    create_preview()[1:10,]
  } else {stop("CSV not formatted correctly")}
})
```

# Tab 2

## {.sidebar width="300px"}

:::{.card}
**Dust Metal Source Ratios**

Input your model parameters here. Make sure to scroll down this sidebar to view all available inputs.

<u>Predictor Selection</u>
:::

```{r}
# Prompt user to select dust metals to use as predictors
checkboxGroupInput( 
  inputId = "metals_group", 
  label = "Which dust metals to use as predictors?", 
  choices = c("Fe" = "Fe", 
              "Ca" = "Ca", 
              "Ti" = "Ti" 
  ), 
  selected = c("Fe", "Ca", "Ti")
)
```

:::{.card}
<u>Rolling Regression Parameters</u>
:::

```{r}
# Prompt user to select window size
numericInput( 
  inputId = "window_size1", 
  label = "Window size (pts) (*):", 
  value = 24, 
  min = 10, 
  max = 100 
)
```

:::{.card}
(*) Note to users: consider time resolution of your data when specifying
:::

```{r}
# Prompt user to select correlation coefficient threshold
numericInput( 
  inputId = "corr_threshold1", 
  label = "Correlation coefficient threshold, R:", 
  value = 0.8, 
  min = 0.7, 
  max = 0.99 
)
```

:::{.card}
<u>Filtering Inputs</u>
:::

```{r}
# Prompt user to select dust cutoff
numericInput( 
  inputId = "dust_cutoff", 
  label = "K/Dust cutoff:", 
  value = 0.5, 
  min = 0.25, 
  max = 1 
)
```

:::{.card}
Click 'Submit' to calculate dust metal source ratios with these parameters for the data you uploaded in Tab 1
:::

```{r}
# Submit button
input_task_button("submit_button_tab2", "Submit")
tags$br()
```

Download a CSV file of the processed data:

```{r}
# Download button
downloadButton(outputId = "dl", label = "Table Download")
tags$br()
```

## First Column

### Parameters and Ratios {height=40%}

```{r}
#| title: "Model Parameters"
# Output the text of selected model parameters
verbatimTextOutput("model_params_tab2")
```


```{r}
#| title: "Dust Metal Source Ratios"
# Output the table of dust metal source ratios
tableOutput("rats_table_tab2")
```

### Diagnostic Plots

```{r}
#| title: "Diagnostic Plot for K/Fe"
# Output lit values + diagnostics for K/Fe
plotlyOutput("KFe_plot_tab2", height = "100%", width = "100%")
```

```{r}
#| title: "Diagnostic Plot for K/Ca"
# Output lit values + diagnostics for K/Ca
plotlyOutput("KCa_plot_tab2", height = "100%", width = "100%")
```

```{r}
#| title: "Diagnostic Plot for K/Ti"
# Output lit values + diagnostics for K/Ti
plotlyOutput("KTi_plot_tab2", height = "100%", width = "100%")
```

```{r}
#| context: server

# Set value_tab2 to 0 to keep track if Tab 2 has successfully output results
value_tab2 <- reactiveVal(0)

# Read in literature values for later
dustRats_forSPARK_formatted <- read.csv("dustRats_forSPARK_formatted.csv")

# Create an InputValidator object
iv <- InputValidator$new()

# Add validation rules for Tab 2
iv$add_rule("window_size1", sv_between(10, 100))
iv$add_rule("corr_threshold1", sv_between(0.7, 0.99))
iv$add_rule("dust_cutoff", sv_between(0.25, 1))

# Start displaying errors if the rules fail
iv$enable()

# Prep the CSV from Tab 1 for further computation
prep_tab2 <- reactive({
  # Return nothing if no file is uploaded
  if (is.null(input$file0)) {
    return(NULL)
  }
  
  # If inspection passes, read in uploaded file
  if (inspect_file() == "Success! Your data is formatted properly."){
    fullsite <- utils::read.csv(input$file0$datapath)
    
    # Comment this out because we're not using local_time anymore
    # for (i in 1:nrow(fullsite)){
    #   # Format value_datetime column according to the time zone and selected timestamp
    #   fullsite$value_datetime[i] <- as.character(as.POSIXct(fullsite$value_datetime[i], tz = fullsite$timezone[i], format = input$timestamp_string))
    #   fullsite$local_time[i] <- as.character(with_tz(fullsite$value_datetime[i], tzone = "America/New_York"))
    #   }
    
    # Create an empty list to hold results
    df_list <- list()
    # For each unique timezone...
    for (a_timezone in unique(fullsite$timezone)){
      sub_df <- fullsite %>%
        # Filter to the rows with that timezone
        filter(timezone == a_timezone) %>%
        # Format value_datetime column according to the time zone and selected timestamp
        mutate(value_datetime = as.character(as.POSIXct(value_datetime, tz = a_timezone, format = input$timestamp_string))) 
      
      # Save result
      df_list[[a_timezone]] <- sub_df
    }
    
    fullsite <- df_list %>%
      # Combine results altogether
      purrr::list_rbind(x = .)
    
    fullsite <- fullsite |>
      dplyr::mutate(K_dust_rat = value_K/(1.4*value_Ca+1.36*value_Fe+1.67*value_Ti)) # add on a column for the K/Dust ratio (used later)
    
    return(fullsite)
  } else {
    stop("CSV not formatted correctly; please check error message on Tab 1")
  }
})

# Do rolling regression for K/Fe
roll_KFe_tab2 <- reactive({
  
  if ("Fe" %in% input$metals_group) {
    
    # Create a Progress object
    progress1 <- shiny::Progress$new(min=0, max=2)
    # Make sure it closes when we exit this reactive, even if there's an error
    on.exit(progress1$close())
    # Set the initial message and value of the progress bar
    progress1$set(message = "Executing rolling regression for K/Fe...",
                  detail = "Please wait, this may take a while.",
                  value = 0)
    
    resultsKFe <- rolling_regression(prep_tab2(), "value_K","value_Fe","value_datetime",
                                     iqr_threshold = 3,
                                     pearson_threshold = input$corr_threshold1,
                                     window_size = input$window_size1,
                                     step_size = 1)
    
    # Update progress bar
    progress1$set(message = "Executing rolling regression for K/Fe...", 
                  detail = "Please wait, this may take a while.",
                  value = 1.5)
    Sys.sleep(0.5)
    
    resultsKFe <- list_to_df(resultsKFe)
    resultsKFe_filt <- dustrat_filter(resultsKFe,Kdustrat_cutoff = input$dust_cutoff)
    
    # Update progress bar 
    progress1$set(message = "Executing rolling regression for K/Fe...DONE", 
                  detail = "",
                  value = 2)
    Sys.sleep(0.5)
    
    return(resultsKFe_filt)
  } else {
    return(NULL)
  }
})

# Do rolling regression for K/Ca
roll_KCa_tab2 <- reactive({
  
  if ("Ca" %in% input$metals_group){
    
    # Create a Progress object
    progress2 <- shiny::Progress$new(min=0, max=2)
    # Make sure it closes when we exit this reactive, even if there's an error
    on.exit(progress2$close())
    # Set the initial message and value of the progress bar
    progress2$set(message = "Executing rolling regression for K/Ca...", 
                  detail = "Please wait, this may take a while.",
                  value = 0)
    
    resultsKCa <- rolling_regression(prep_tab2(), "value_K","value_Ca","value_datetime",
                                     iqr_threshold = 3,
                                     pearson_threshold = input$corr_threshold1,
                                     window_size = input$window_size1,
                                     step_size = 1)
    
    # Update progress bar 
    progress2$set(message = "Executing rolling regression for K/Ca...", 
                  detail = "Please wait, this may take a while.",
                  value = 1.5)
    Sys.sleep(0.5)

    resultsKCa <- list_to_df(resultsKCa)
    resultsKCa_filt <- dustrat_filter(resultsKCa,Kdustrat_cutoff = input$dust_cutoff)
    
    # Update progress bar 
    progress2$set(message = "Executing rolling regression for K/Ca...DONE", 
                  detail = "",
                  value = 2)
    Sys.sleep(0.5)
    
    return(resultsKCa_filt)
  } else {
    return(NULL)
  }
})

# Do rolling regression for K/Ti
roll_KTi_tab2 <- reactive({
  
  if ("Ti" %in% input$metals_group){
    
    # Create a Progress object
    progress3 <- shiny::Progress$new(min=0, max=2)
    # Make sure it closes when we exit this reactive, even if there's an error
    on.exit(progress3$close())
    # Set the initial message and value in the progress bar
    progress3$set(message = "Executing rolling regression for K/Ti...", 
                  detail = "Please wait, this may take a while.",
                  value = 0)
    
    resultsKTi <- rolling_regression(prep_tab2(), "value_K","value_Ti","value_datetime",
                                     iqr_threshold = 3,
                                     pearson_threshold = input$corr_threshold1,
                                     window_size = input$window_size1,
                                     step_size = 1)
    
    # Update progress bar 
    progress3$set(message = "Executing rolling regression for K/Ti...", 
                  detail = "Please wait, this may take a while.",
                  value = 1.5)
    Sys.sleep(0.5)

    resultsKTi <- list_to_df(resultsKTi)
    resultsKTi_filt <- dustrat_filter(resultsKTi,Kdustrat_cutoff = input$dust_cutoff)
    
    # Update progress bar 
    progress3$set(message = "Executing rolling regression for K/Ti...DONE", 
                  detail = "",
                  value = 2)
    Sys.sleep(0.5)
    
    return(resultsKTi_filt)
  } else {
    return(NULL)
  }
})

# Combine the results for all metals together into a dataframe
combine_metal_rats <- reactive({
  
  if (!is.null(roll_KFe_tab2())){
    KFe_rats <- roll_KFe_tab2() %>%
      # Create a Metal column
      mutate(Metal = "Fe")
  } else {KFe_rats <- NULL}
  
  if (!is.null(roll_KCa_tab2())){
    KCa_rats <- roll_KCa_tab2() %>%
      # Create a Metal column
      mutate(Metal = "Ca")
  } else {KCa_rats <- NULL}
  
  if (!is.null(roll_KTi_tab2())){
    KTi_rats <- roll_KTi_tab2() %>%
      # Create a Metal column
      mutate(Metal = "Ti")
  } else {KTi_rats <- NULL}
  
  # Combine the dataframes together
  metal_rats <- rbind(KFe_rats,KCa_rats,KTi_rats)
  
  # Select columns to include
  metal_rats <- metal_rats %>%
    select(Metal, slope_odr, intercept_odr, r, npts, start_datetime, end_datetime, start_index, end_index, 
           predictor_avg, response_avg, Kdustrat_avg, snr_predictor, snr_response)
  
  # Set value_tab2 to 1 to signal successful completion 
  value_tab2(1)
  
  return(metal_rats)
  
})

# Render model parameter inputs as text
output$model_params_tab2 <- renderText({
  shiny::validate(
    need(input$file0, "Name of uploaded file will be shown here after you upload a file and click 'Submit':")
  )
  
  # Don't proceed if any input is invalid
  req(iv$is_valid())
  
  paste0("Your current file: ", input$file0$name, 
        "\nSelected predictors: ", toString(input$metals_group),
        "\nWindow size: ", input$window_size1,
        "\nCorrelation coefficient threshold: ", input$corr_threshold1,
        "\nK/Dust cutoff: ", input$dust_cutoff)
}) %>% 
  bindEvent(input$submit_button_tab2)

# Render dust metal source ratios table
output$rats_table_tab2 <- renderTable({
  shiny::validate(
    need(input$file0, "Results will be shown here after you upload a file and click 'Submit':")
  )
  
  # Don't proceed if any input is invalid
  req(iv$is_valid())
  
  # Combine the dust metal ratios when the Submit button is clicked
  combine_metal_rats()}, digits = 3) %>% 
  bindEvent(input$submit_button_tab2)

# Ratios table download button
output$dl <- downloadHandler(
  # Create the output file name
  filename = function(){
    paste0("custom_table_", Sys.Date(), ".csv")
  },
  # Save ratios table as CSV
  content = function(file) {
    readr::write_csv(combine_metal_rats(), file)
    
  }
)

# Filter K/Fe results to prep for plotting
prep_KFe_plot_tab2 <- reactive({
  
  if (!is.null(roll_KFe_tab2())){
    resultsKFe_filt_v2 <- roll_KFe_tab2() |>
      filter((slope_odr > quantile(slope_odr,na.rm=TRUE,probs = 0.05)) & (slope_odr < quantile(slope_odr,na.rm=TRUE,probs = 0.95)))
    
    return(resultsKFe_filt_v2)
  } else {
    return(NULL)
  }
})

# Filter K/Ca results to prep for plotting
prep_KCa_plot_tab2 <- reactive({
  if (!is.null(roll_KCa_tab2())){
    resultsKCa_filt_v2 <- roll_KCa_tab2() |>
      filter((slope_odr > quantile(slope_odr,na.rm=TRUE,probs = 0.05)) & (slope_odr < quantile(slope_odr,na.rm=TRUE,probs = 0.95)))
    
    return(resultsKCa_filt_v2)
  } else {
    return(NULL)
  }
})

# Filter K/Ti results to prep for plotting
prep_KTi_plot_tab2 <- reactive({
  if (!is.null(roll_KTi_tab2())){
    resultsKTi_filt_v2 <- roll_KTi_tab2() |>
      filter((slope_odr > quantile(slope_odr,na.rm=TRUE,probs = 0.05)) & (slope_odr < quantile(slope_odr,na.rm=TRUE,probs = 0.95)))
    
    return(resultsKTi_filt_v2)
  } else {
    return(NULL)
  }
})

# Render lit values + diagnostics plot for K/Fe
output$KFe_plot_tab2 <- renderPlotly({
  
  # ### Doesnt work for renderPlotly, can test again in future ###
  # shiny::validate(
  #   need(input$file0, "Upload a file and click 'Submit' first")
  # )
  # 
  # # Don't proceed if any input is invalid
  # req(iv$is_valid())
  # 
  
  if(is.null(input$file0)){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (inspect_file() != "Success! Your data is formatted properly."){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$window_size1 < 10 | input$window_size1 > 100){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$corr_threshold1 < 0.7 | input$corr_threshold1 > 0.99){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$dust_cutoff < 0.25 | input$dust_cutoff > 1){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (!is.null(prep_KFe_plot_tab2())){
    
    KFe_lit <- dustRats_forSPARK_formatted %>%
      # Filter for KFe
      filter(variable == "KFe") %>%
      # Pivot the percentile and value columns to long format
      pivot_wider(names_from = percentile,
                  values_from = value) %>%
      # Create a custom ordering for Paved, Unpaved, Soil
      mutate(myorder = case_when(
        dust_type == "Paved Road" ~ 1,
        dust_type == "Unpaved Road" ~ 2,
        dust_type == "Soil" ~ 3
      )) %>%
      # Arrange rows by descending order
      arrange(desc(myorder)) %>%
      # Convert the custom ordering column into a factor
      mutate(dust_type = factor(dust_type, dust_type))
    
    # Find max 98th percentile in lit values
    max_KFe_lit <- max(KFe_lit$percentile_98)
    # Find max slope_odr
    max_KFe <- max(prep_KFe_plot_tab2()$slope_odr)
    
    # Grab the higher value out of 98th percentile or slope_odr
    KFe_xmax <- max(max_KFe, max_KFe_lit)
    
    # Create lollipop plot for literature values
    p1_KFe <- ggplot(KFe_lit) +
      geom_segment(aes(x=dust_type, xend=dust_type, y=percentile_2, yend=percentile_98), color="black") +
      geom_point(aes(x=dust_type, y=percentile_2, text = paste("dust type:", dust_type, "\n2nd percentile:", percentile_2)), color="#FDE725FF", size=3) +
      geom_point(aes(x=dust_type, y=median, text = paste("dust type:", dust_type, "\nmedian:", median)), color="#238A8DFF", size=3) +
      geom_point(aes(x=dust_type, y=percentile_98, text = paste("dust type:", dust_type, "\n98th percentile:", percentile_98)), color="#440154FF", size=3) +
      coord_flip()+
      theme_minimal() +
      theme(
        legend.position = "none",
        panel.grid.minor = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_blank()
      ) +
      scale_y_continuous(limits = c(0, KFe_xmax))
    
    # Create diagnostic plot
    p2_KFe <- ggplot(prep_KFe_plot_tab2(), mapping = aes(x = slope_odr)) +
      geom_histogram(aes(y = ..count..), bins = 40, fill = 'green', color = 'grey30') +
      geom_vline(aes(xintercept = median(median(prep_KFe_plot_tab2()$slope_odr)), text = paste("median:", median(median(prep_KFe_plot_tab2()$slope_odr)))), color = "red", linetype = "dashed", size = 1) +
      labs(x = "K/Fe", y = "Frequency") +
      scale_y_continuous(expand = c(0,0))+
      scale_x_continuous(limits = c(0,KFe_xmax), expand = c(0,0))+
      theme_classic()
    
    # Convert plots to plotly
    ply1_KFe <- ggplotly(p1_KFe, tooltip = c("text"))
    ply2_KFe <- ggplotly(p2_KFe, tooltip = c("y", "text"))
    
    # Plot them together with plotly::subplot()
    subplot(ply1_KFe, ply2_KFe, nrows=2, titleY = TRUE, titleX = TRUE,
            heights = c(0.4, 0.6), margin = c(0, 0, 0.14, 0.05))%>%
      layout(annotations = list(
        list(x = 0.02, y = 1.05, text = "Literature Values", showarrow = FALSE, xref='paper', yref='paper', size=.8),
        list(x = 0.02, y = 0.5, text = "Diagnostics", showarrow = FALSE, xref='paper', yref='paper', size=.8)),
        margin = list(t = 20)) # Increase top margin
  }
}) %>% 
  bindEvent(input$submit_button_tab2)

# Render lit values + diagnostics plot for K/Ca
output$KCa_plot_tab2 <- renderPlotly({
  
  # ### Doesnt work for renderPlotly, can test again in future ###
  # shiny::validate(
  #   need(input$file0, "Upload a file and click 'Submit' first")
  # )
  # 
  # # Don't proceed if any input is invalid
  # req(iv$is_valid())
  
  if(is.null(input$file0)){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (inspect_file() != "Success! Your data is formatted properly."){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$window_size1 < 10 | input$window_size1 > 100){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$corr_threshold1 < 0.7 | input$corr_threshold1 > 0.99){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$dust_cutoff < 0.25 | input$dust_cutoff > 1){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (!is.null(prep_KCa_plot_tab2())){
    KCa_lit <- dustRats_forSPARK_formatted %>%
      # Filter for KCa
      filter(variable == "KCa") %>%
      # Pivot the percentile and value columns to long format
      pivot_wider(names_from = percentile,
                  values_from = value) %>%
      # Create a custom ordering for Paved, Unpaved, Soil
      mutate(myorder = case_when(
        dust_type == "Paved Road" ~ 1,
        dust_type == "Unpaved Road" ~ 2,
        dust_type == "Soil" ~ 3
      )) %>%
      # Arrange rows by descending order
      arrange(desc(myorder)) %>%
      # Convert the custom ordering column into a factor
      mutate(dust_type = factor(dust_type, dust_type))
    
    # Find max 98th percentile in lit values
    max_KCa_lit <- max(KCa_lit$percentile_98)
    # Find max slope_odr
    max_KCa <- max(prep_KCa_plot_tab2()$slope_odr)
    
    # Grab the higher value out of 98th percentile or slope_odr
    KCa_xmax <- max(max_KCa, max_KCa_lit)
    
    # Create lollipop plot for literature values
    p1_KCa <- ggplot(KCa_lit) +
      geom_segment(aes(x=dust_type, xend=dust_type, y=percentile_2, yend=percentile_98), color="black") +
      geom_point(aes(x=dust_type, y=percentile_2, text = paste("dust type:", dust_type, "\n2nd percentile:", percentile_2)), color="#FDE725FF", size=3) +
      geom_point(aes(x=dust_type, y=median, text = paste("dust type:", dust_type, "\nmedian:", median)), color="#238A8DFF", size=3) +
      geom_point(aes(x=dust_type, y=percentile_98, text = paste("dust type:", dust_type, "\n98th percentile:", percentile_98)), color="#440154FF", size=3) +
      coord_flip()+
      theme_minimal() +
      theme(
        legend.position = "none",
        panel.grid.minor = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_blank()
      )  +
      scale_y_continuous(limits = c(0, KCa_xmax))
    
    # Create diagnostic plot
    p2_KCa <- ggplot(prep_KCa_plot_tab2(), mapping = aes(x = slope_odr)) +
      geom_histogram(aes(y = ..count..), bins = 40, fill = 'green', color = 'grey30') +
      geom_vline(aes(xintercept = median(median(prep_KCa_plot_tab2()$slope_odr)), text = paste("median:", median(median(prep_KCa_plot_tab2()$slope_odr)))), color = "red", linetype = "dashed", size = 1) +
      labs(x = "K/Ca", y = "Frequency") +
      scale_y_continuous(expand = c(0,0))+
      scale_x_continuous(limits = c(0,KCa_xmax), expand = c(0,0))+
      theme_classic()
    
    # Convert plots to plotly
    ply1_KCa <- ggplotly(p1_KCa, tooltip = c("text"))
    ply2_KCa <- ggplotly(p2_KCa, tooltip = c("y", "text"))
    
    # Plot them together with plotly::subplot()
    subplot(ply1_KCa, ply2_KCa, nrows=2, titleY = TRUE, titleX = TRUE,
            heights = c(0.4, 0.6), margin = c(0, 0, 0.14, 0.05))%>%
      layout(annotations = list(
        list(x = 0.02, y = 1.05, text = "Literature Values", showarrow = FALSE, xref='paper', yref='paper', size=.8),
        list(x = 0.02, y = 0.5, text = "Diagnostics", showarrow = FALSE, xref='paper', yref='paper', size=.8)),
        margin = list(t = 20)) # Increase top margin
  } 
}) %>% 
  bindEvent(input$submit_button_tab2)

# Render lit values + diagnostics plot for K/Ti
output$KTi_plot_tab2 <- renderPlotly({
  
  # ### Doesnt work for renderPlotly, can test again in future ###
  # shiny::validate(
  #   need(input$file0, "Upload a file and click 'Submit' first")
  # )
  # 
  # # Don't proceed if any input is invalid
  # req(iv$is_valid())
  
  if(is.null(input$file0)){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (inspect_file() != "Success! Your data is formatted properly."){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$window_size1 < 10 | input$window_size1 > 100){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$corr_threshold1 < 0.7 | input$corr_threshold1 > 0.99){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$dust_cutoff < 0.25 | input$dust_cutoff > 1){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (!is.null(prep_KTi_plot_tab2())){
    
    KTi_lit <- dustRats_forSPARK_formatted %>%
      # Filter for KTi
      filter(variable == "KTi") %>%
      # Pivot the percentile and value columns to long format
      pivot_wider(names_from = percentile,
                  values_from = value) %>%
      # Create a custom ordering for Paved, Unpaved, Soil
      mutate(myorder = case_when(
        dust_type == "Paved Road" ~ 1,
        dust_type == "Unpaved Road" ~ 2,
        dust_type == "Soil" ~ 3
      )) %>%
      # Arrange rows by descending order
      arrange(desc(myorder)) %>%
      # Convert the custom ordering column into a factor
      mutate(dust_type = factor(dust_type, dust_type))
    
    # Find max 98th percentile in lit values
    max_KTi_lit <- max(KTi_lit$percentile_98)
    # Find max slope_odr
    max_KTi <- max(prep_KTi_plot_tab2()$slope_odr)
    
    # Grab the higher value out of 98th percentile or slope_odr
    KTi_xmax <- max(max_KTi, max_KTi_lit)
    
    # Create lollipop plot for literature values
    p1_KTi <- ggplot(KTi_lit) +
      geom_segment(aes(x=dust_type, xend=dust_type, y=percentile_2, yend=percentile_98), color="black") +
      geom_point(aes(x=dust_type, y=percentile_2, text = paste("dust type:", dust_type, "\n2nd percentile:", percentile_2)), color="#FDE725FF", size=3) +
      geom_point(aes(x=dust_type, y=median, text = paste("dust type:", dust_type, "\nmedian:", median)), color="#238A8DFF", size=3) +
      geom_point(aes(x=dust_type, y=percentile_98, text = paste("dust type:", dust_type, "\n98th percentile:", percentile_98)), color="#440154FF", size=3) +
      coord_flip()+
      theme_minimal() +
      theme(
        legend.position = "none",
        panel.grid.minor = element_blank(),
        axis.title.y = element_blank(),
        axis.title.x = element_blank()
      ) +
      scale_y_continuous(limits = c(0, KTi_xmax))
    
    # Create diagnostic plot
    p2_KTi <- ggplot(prep_KTi_plot_tab2(), mapping = aes(x = slope_odr)) +
      geom_histogram(aes(y = ..count..), bins = 40, fill = 'green', color = 'grey30') +
      geom_vline(aes(xintercept = median(median(prep_KTi_plot_tab2()$slope_odr)), text = paste("median:", median(median(prep_KTi_plot_tab2()$slope_odr)))), color = "red", linetype = "dashed", size = 1) +
      labs(x = "K/Ti", y = "Frequency") +
      scale_y_continuous(expand = c(0,0))+
      scale_x_continuous(limits = c(0,KTi_xmax), expand = c(0,0))+
      theme_classic()
    
    # Convert plots to plotly
    ply1_KTi <- ggplotly(p1_KTi, tooltip = c("text"))
    ply2_KTi <- ggplotly(p2_KTi, tooltip = c("y", "text"))
    
    # Plot them together with plotly::subplot()
    subplot(ply1_KTi, ply2_KTi, nrows=2, titleY = TRUE, titleX = TRUE,
            heights = c(0.4, 0.6), margin = c(0, 0, 0.14, 0.05))%>%
      layout(annotations = list(
        list(x = 0.02, y = 1.05, text = "Literature Values", showarrow = FALSE, xref='paper', yref='paper', size=.8),
        list(x = 0.02, y = 0.5, text = "Diagnostics", showarrow = FALSE, xref='paper', yref='paper', size=.8)),
        margin = list(t = 20)) # Increase top margin
  }
}) %>% 
  bindEvent(input$submit_button_tab2)
```

# Tab 3

## {.sidebar width="300px"}

:::{.card}
**Biomass Burning OA/K Ratios**

Input your model parameters here. Make sure to scroll down this sidebar to view all available inputs.

<u>Rolling Regression Parameters</u>
:::

```{r}
numericInput( 
  inputId = "window_size2", 
  label = "Window size (pts) (*):", 
  value = 24, 
  min = 10, 
  max = 100 
)
```

:::{.card}
(*) Note to users: consider time resolution of your data when specifying
:::

```{r}
numericInput( 
  inputId = "corr_threshold2", 
  label = "Correlation coefficient threshold, R:", 
  value = 0.8, 
  min = 0.7, 
  max = 0.99 
)
```

:::{.card}
<u>Optional Inputs</u>
:::

```{r}
numericInput( 
  inputId = "om_oc", 
  label = "OM/OC ratio:", 
  value = NA, 
  min = 1
)

selectInput(
  inputId = "season_specific",
  label = "Use season-specific ratio distributions?",
  choices = c("No",
              "Yes"),
  selected = "No"
) 

```

:::{.card}
Click 'Submit' to calculate biomass burning OA/K ratios with these parameters for the data you uploaded in Tab 1
:::

```{r}
input_task_button("submit_button_tab3", "Submit")
tags$br()
```

Download a CSV file of the processed data:

```{r}
# Download button
downloadButton(outputId = "dl_tab3", label = "Table Download")
tags$br()
```

## First Column

### Parameters and Ratios {height=40%}

```{r}
#| title: "Model Parameters"
# Output the text of selected model parameters
verbatimTextOutput("model_params_tab3")
```


```{r}
#| title: "Biomass Burning Ratios"
# Output the table of biomass burning ratios
tableOutput("rats_table_tab3")
```

### Plots

```{r}
#| title: "OA/K"
# Output distribution of OA/K
plotlyOutput("OAK_plot_tab3", height = "100%", width = "100%")
```

```{r}
#| title: "OC/K"
# Output distribution of OC/K if an OM/OC ratio is supplied
plotlyOutput("OCK_plot_tab3", height = "100%", width = "100%")
```

```{r}
#| context: server

# Set value_tab3 to 0 to keep track if Tab 2 has successfully output results
value_tab3 <- reactiveVal(0)

# Read in literature values for later
BBRats_forSPARK_formatted <- read.csv("BBRats_forSPARK_formatted.csv")

# Create an InputValidator object
iv2 <- InputValidator$new()

# Add validation rules for Tab 3
iv2$add_rule("window_size2", sv_between(10, 100))
iv2$add_rule("corr_threshold2", sv_between(0.7, 0.99))
iv2$add_rule("om_oc", sv_optional())
iv2$add_rule("om_oc", sv_gt(1))

# Start displaying errors if the rules fail
iv2$enable()

# Prep the CSV from Tab 1 for further computation
prep_tab3 <- reactive({
  # Return nothing if no file is uploaded
  if (is.null(input$file0)) {
    return(NULL)
  }
  
  # If inspection passes, read in uploaded file
  if (inspect_file() == "Success! Your data is formatted properly."){
    fullsite <- utils::read.csv(input$file0$datapath)
    
    # Comment this out because we're not using local_time anymore
    # for (i in 1:nrow(fullsite)){
    #   # Format value_datetime column according to the time zone and selected timestamp
    #   fullsite$value_datetime[i] <- as.character(as.POSIXct(fullsite$value_datetime[i], tz = fullsite$timezone[i], format = input$timestamp_string))
    #   fullsite$local_time[i] <- as.character(with_tz(fullsite$value_datetime[i], tzone = "America/New_York"))
    #   }
    
    # Create an empty list to hold results
    df_list <- list()
    # For each unique timezone...
    for (a_timezone in unique(fullsite$timezone)){
      sub_df <- fullsite %>%
        # Filter to the rows with that timezone
        filter(timezone == a_timezone) %>%
        # Format value_datetime column according to the time zone and selected timestamp
        mutate(value_datetime = as.character(as.POSIXct(value_datetime, tz = a_timezone, format = input$timestamp_string))) 
      
      # Save result
      df_list[[a_timezone]] <- sub_df
    }
    
    fullsite <- df_list %>%
      # Combine results altogether
      purrr::list_rbind(x = .)
    
    return(fullsite)
  } else {
    stop("CSV not formatted correctly; please check error message on Tab 1")
  }
})

# Do rolling regression for OA vs K
roll_OAK_tab3 <- reactive({
  
  
  # Create a Progress object
  progress4 <- shiny::Progress$new(min=0, max=2)
  # Make sure it closes when we exit this reactive, even if there's an error
  on.exit(progress4$close())
  # Set the initial message and value of the progress bar
  progress4$set(message = "Executing rolling regression for OA/K...",
                detail = "Please wait, this may take a while.",
                value = 0)
  
  results_OA_K <- rolling_regression_bioburn(prep_tab3(), "value_OA","value_K","value_datetime",
                                             window_size = input$window_size2, 
                                             step_size = 1, 
                                             pearson_threshold = input$corr_threshold2)
  
  # Update progress bar
  progress4$set(message = "Executing rolling regression for OA/K...", 
                detail = "Please wait, this may take a while.",
                value = 1.5)
  Sys.sleep(0.5)
  
  results_OA_K <- list_to_df(results_OA_K)
  results_OA_K_filt <- bbrat_filter(results_OA_K)
  
  # Update progress bar 
  progress4$set(message = "Executing rolling regression for OA/K...DONE", 
                detail = "",
                value = 2)
  Sys.sleep(0.5)
  
  # Set value_tab3 to 1 to signal successful completion 
  value_tab3(1)
  
  return(results_OA_K_filt)
  
})

# Render model parameter inputs as text
output$model_params_tab3 <- renderText({
  shiny::validate(
    need(input$file0, "Name of uploaded file will be shown here after you upload a file and click 'Submit':")
  )
  
  # Don't proceed if any input is invalid
  req(iv2$is_valid())
  
  paste0("Your current file: ", input$file0$name, 
        "\nWindow size: ", input$window_size2,
        "\nCorrelation coefficient threshold: ", input$corr_threshold2,
        "\nOM/OC: ", input$om_oc,
        "\nSeason-specific ratio distributions: ", input$season_specific)
}) %>% 
  bindEvent(input$submit_button_tab3)

# Render biomass burning ratios table
output$rats_table_tab3 <- renderTable({
  shiny::validate(
    need(input$file0, "Results will be shown here after you upload a file and click 'Submit':")
  )
  
  # Don't proceed if any input is invalid
  req(iv2$is_valid())
  
  # Combine the dust metal ratios when the Submit button is clicked
  roll_OAK_tab3()}, digits = 3) %>% 
  bindEvent(input$submit_button_tab3)

# Ratios table download button
output$dl_tab3 <- downloadHandler(
  # Create the output file name
  filename = function(){
    paste0("custom_table_", Sys.Date(), ".csv")
  },
  # Save ratios table as CSV
  content = function(file) {
    readr::write_csv(roll_OAK_tab3(), file)
    
  }
)

# Filter OA/K results to prep for plotting
prep_OAK_plot_tab3 <- reactive({
  
  if (!is.null(roll_OAK_tab3())){
    results_OA_K_filt_v2 <- roll_OAK_tab3() |>
  filter((slope_odr > quantile(slope_odr,na.rm=TRUE,probs = 0.05)) & (slope_odr < quantile(slope_odr,na.rm=TRUE,probs = 0.95)))
    
    return(results_OA_K_filt_v2)
  } else {
    return(NULL)
  }
})

# Render distribution plot for OA/K
output$OAK_plot_tab3 <- renderPlotly({
  
  # ### Doesnt work for renderPlotly, can test again in future ###
  # shiny::validate(
  #   need(input$file0, "Upload a file and click 'Submit' first")
  # )
  # 
  # # Don't proceed if any input is invalid
  # req(iv2$is_valid())
  
  if(is.null(input$file0)){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (inspect_file() != "Success! Your data is formatted properly."){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$window_size2 < 10 | input$window_size2 > 100){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$corr_threshold2 < 0.7 | input$corr_threshold2 > 0.99){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (!is.na(input$om_oc) & input$om_oc <= 1){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (!is.null(prep_OAK_plot_tab3())){
    
    if(input$season_specific == "No") {
      
      med_val <-  prep_OAK_plot_tab3() |>
        summarise(value = median(slope_odr,na.rm=TRUE))
      
      med_val <- med_val$value
      
      # Create distribution plot
      p_OAK <- ggplot(prep_OAK_plot_tab3(), mapping = aes(x = slope_odr*1000)) +
        geom_histogram(aes(y = ..count..), bins = 40, fill = 'green', color = 'grey30') +
        geom_vline(aes(xintercept = med_val*1000, text = paste("median:", med_val*1000)), color = "red", linetype = "dashed", size = 1) +
        labs(title = "Distribution of OA/K", x = "OA/K", y = "Frequency") +
        scale_y_continuous(expand = c(0,0))+
        scale_x_continuous(limits = c(0,NA), expand = c(0,0))+
        theme_classic()
      
      # Convert plot to plotly
      ply_OAK <- ggplotly(p_OAK, tooltip = c("y", "text"))
      return(ply_OAK)
    } else if (input$season_specific == "Yes") {
      # add on the seasonal groupings to make four panels
      results_OA_K_filt_v3 <- prep_OAK_plot_tab3() |>
        mutate(month = month(start_datetime)) |>
        mutate(season = case_when(month %in% c(12,1,2,3) ~ "DJFM",
                                  month %in% c(4,5) ~ "AM",
                                  month %in% c(6,7,8,9) ~ "JJAS",
                                  month %in% c(10,11) ~ "ON"))
      
      
      med_vals <-  results_OA_K_filt_v3 |>
        group_by(season) |>
        summarise(value = median(slope_odr,na.rm=TRUE))
      
      med_vals <- med_vals$value
      
      
      # Create season-specific distribution plot
      p_OAK_season <- ggplot(results_OA_K_filt_v3, mapping = aes(x = slope_odr*1000)) +
        geom_histogram(aes(y = ..count..), bins = 40, fill = 'green', color = 'grey30') +
        labs(title = "Season-specific distribution of OA/K", x = "OA/K", y = "Frequency") +
        scale_y_continuous(expand = c(0,0))+
        scale_x_continuous(limits = c(0,NA), expand = c(0,0))+
        theme_classic() +
        facet_wrap(vars(season))
      
      # Convert plot to plotly
      ply_OAK_season <- ggplotly(p_OAK_season, tooltip = c("y"))
      
      return(ply_OAK_season)
    }
  } 
}) %>% 
  bindEvent(input$submit_button_tab3)

# Render distribution plot for OC/K
output$OCK_plot_tab3 <- renderPlotly({
  
  # ### Doesnt work for renderPlotly, can test again in future ###
  # shiny::validate(
  #   need(input$file0, "Upload a file and click 'Submit' first")
  # )
  # 
  # # Don't proceed if any input is invalid
  # req(iv2$is_valid())
  
  if(is.null(input$file0)){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (inspect_file() != "Success! Your data is formatted properly."){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$window_size2 < 10 | input$window_size2 > 100){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (input$corr_threshold2 < 0.7 | input$corr_threshold2 > 0.99){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (!is.na(input$om_oc) & input$om_oc <= 1){
    p <-ggplot()
    return(ggplotly(p))
  }
  
  if (!is.null(prep_OAK_plot_tab3()) & !is.na(input$om_oc)){
    
    if (input$om_oc > 1){
      
      OCK_lit <- BBRats_forSPARK_formatted %>%
        # Pivot the percentile and value columns to long format
        pivot_wider(names_from = percentile,
                    values_from = value) %>%
        # Create a custom ordering for Agricultural Residues, Grasslands, etc
        mutate(myorder = case_when(
          source == "Agricultural Residues" ~ 1,
          source == "Grasslands" ~ 2,
          source == "Tropical Forests" ~ 3,
          source == "Temperate Forests" ~ 4,
          source == "RWC" ~ 5
        )) %>%
        # Arrange rows by descending order
        arrange(desc(myorder)) %>%
        # Convert the custom ordering column into a factor
        mutate(source = factor(source, source))
      
      # Find max 75th percentile in lit values
      max_OCK_lit <- max(OCK_lit$percentile_75)
      # Find max slope_odr
      max_OCK <- max(prep_OAK_plot_tab3()$slope_odr)
      
      # Grab the higher value out of 75th percentile or slope_odr
      OCK_xmax <- max(max_OCK, max_OCK_lit)
      
      # Create lollipop plot for literature values
      p1_OCK <- ggplot(OCK_lit) +
        geom_segment(aes(x=source, xend=source, y=percentile_25, yend=percentile_75), color="black") +
        geom_point(aes(x=source, y=percentile_25, text = paste("source:", source, "\n25th percentile:", percentile_25)), color="#FDE725FF", size=3) +
        geom_point(aes(x=source, y=median, text = paste("source:", source, "\nmedian:", median)), color="#238A8DFF", size=3) +
        geom_point(aes(x=source, y=percentile_75, text = paste("source:", source, "\n75th percentile:", percentile_75)), color="#440154FF", size=3) +
        geom_point(aes(x=source, y=hardwood, text = paste("RWC type:", "Hardwoods", "\npercentile:", hardwood)), color="maroon", size=3) +
        geom_point(aes(x=source, y=softwood, text = paste("RWC type:", "Softwoods", "\npercentile:", softwood)), color="maroon", size=3) +
        coord_flip()+
        theme_minimal() +
        theme(
          legend.position = "none",
          panel.grid.minor = element_blank(),
          axis.title.y = element_blank(),
          axis.title.x = element_blank()
        ) +
      scale_y_continuous(limits = c(0, OCK_xmax))
      
      # Create distribution plot
      p2_OCK <- ggplot(prep_OAK_plot_tab3(), mapping = aes(x = (slope_odr*1/(input$om_oc))*1000)) +
        geom_histogram(aes(y = ..count..), bins = 40, fill = 'green', color = 'grey30') +
        labs(x = "OC/K", y = "Frequency") +
        scale_y_continuous(expand = c(0,0))+
        scale_x_continuous(limits = c(0,OCK_xmax), expand = c(0,0))+
        theme_classic()
      
      # Convert plot to plotly
      ply1_OCK <- ggplotly(p1_OCK, tooltip = c("text"))
      ply2_OCK <- ggplotly(p2_OCK, tooltip = c("y"))
      
      # Plot them together with plotly::subplot()
      ply1_ply2 <- subplot(ply1_OCK, ply2_OCK, nrows=2, titleY = TRUE, titleX = TRUE,
                           heights = c(0.5, 0.5), margin = c(0, 0, 0.14, 0.05))%>%
        layout(annotations = list(
          list(x = 0.02, y = 1.07, text = "Literature Values", showarrow = FALSE, xref='paper', yref='paper', size=.8),
          list(x = 0.02, y = 0.4, text = "Distribution of OC/K", showarrow = FALSE, xref='paper', yref='paper', size=.8)),
          margin = list(t = 20)) # Increase top margin
      
      return(ply1_ply2)
    } else if (input$om_oc <=1 ) {
      p <-ggplot()
      return(ggplotly(p))
    }
  }
  
}) %>% 
  bindEvent(input$submit_button_tab3)

```

# Tab 4

## {.sidebar width="300px"}

:::{.card}
**Monte Carlo Calculation of BBOA**

Input your model parameters here. Make sure to scroll down this sidebar to view all available inputs.

<u>Strontium Firework Cutoff</u>
:::

```{r}
# Prompt user to select strontium firework cutoff
numericInput( 
  inputId = "firework_cutoff", 
  label = "Cutoff (ng/m3):", 
  value = 1, 
  min = 1
)
```

:::{.card}
<u>Monte Carlo Simulation</u>
:::

```{r}
# Prompt user to select number of iterations
numericInput( 
  inputId = "n_iterations", 
  label = "Number of iterations:", 
  value = 100, 
  min = 100, 
  max = 5000 
)
```

:::{.card}
<u>Data Inputs</u>
:::

```{r}
selectInput(
  inputId = "dust_rats",
  label = "Select your dust ratios:",
  choices = c("", 
              "Use ratios that were calculated from Tab 2",
              "Upload my own previously computed ratios"),
  selected = ""
) 

conditionalPanel(
  condition = "input.dust_rats == 'Upload my own previously computed ratios'",
  # Prompt user to upload dust ratios CSV
  fileInput("user_uploaded_dust", "Upload your own previously computed dust ratios here:", accept = ".csv")
)

# Output inspection results
textOutput("inspection_results_dust")
tags$br()

selectInput(
  inputId = "OAK_rats",
  label = "Select your OA/K ratios:",
  choices = c("",
              "Use ratios that were calculated from Tab 3",
              "Upload my own previously computed ratios"),
  selected = ""
) 

conditionalPanel(
  condition = "input.OAK_rats == 'Upload my own previously computed ratios'",
  # Prompt user to upload OAK ratios CSV 
  fileInput("user_uploaded_OAK", "Upload your own previously computed OA/K ratios here:", accept = ".csv")
)

# Output inspection results
textOutput("inspection_results_OAK")
tags$br()
```

:::{.card}
<u>Optional Inputs</u>
:::

```{r}
selectInput(
  inputId = "season_specific2",
  label = "Use season-specific ratio distributions?",
  choices = c("No",
              "Yes"),
  selected = "No"
) 

```

:::{.card}
Click 'Submit' to calculate biomass burning OA via Monte Carlo approach
:::

```{r}
input_task_button("submit_button_tab4", "Submit")
tags$br()
```

Download a CSV file of the processed data:

```{r}
# Download button
downloadButton(outputId = "dl_tab4", label = "Table Download")
tags$br()
```

## First Row 

### Parameters {height=30%}

```{r}
#| title: "Model Parameters"
# Output the text of selected model parameters
verbatimTextOutput("model_params_tab4")
```

### Table

```{r}
#| title: "Estimated BBOA"
# Output the table of estimated biomass burning OA
tableOutput("bboa_table_tab4")
```

```{r}
#| context: server

# Read in for later
seaspray_rats <- read_csv("DEFAULT_SeaSprayRats.csv") # this could be site specific, but using this default is fine.
seaspray_rats <- seaspray_rats |>
  filter(Metal == "Cl") |>
  filter(Value > quantile(Value, probs = 0.05) & Value < quantile(Value,probs = 0.95)) 

# Create an InputValidator object
iv3 <- InputValidator$new()

# Add validation rules for Tab 3
iv3$add_rule("firework_cutoff", sv_gte(1))
iv3$add_rule("n_iterations", sv_between(100, 5000))

# Start displaying errors if the rules fail
iv3$enable()

# Select dust metal ratios data input
dust_rats_tab4 <- reactive({
  # If user wants to use ratios from Tab 2...
  if (input$dust_rats == "Use ratios that were calculated from Tab 2"){
    # If ratios have been successfully calculated...
    if (value_tab2() == 1){
      # Return ratios from Tab 2
      dust_rats_to_use <- combine_metal_rats()
      return(dust_rats_to_use)
    } else {stop("Please calculate on Tab 2 first")}
  # Else if user wants to upload their own ratios...
  } else if (input$dust_rats == "Upload my own previously computed ratios"){
    # Read in uploaded ratios
    dust_rats_to_use <- utils::read.csv(input$user_uploaded_dust$datapath)
    return(dust_rats_to_use)
  }
})

# Select biomass burning OA/K ratios data input
OAK_rats_tab4 <- reactive({
  # If user wants to use ratios from Tab 3...
  if (input$OAK_rats == "Use ratios that were calculated from Tab 3"){
    # If ratios have been successfully calculated...
    if (value_tab3() == 1){
      # Return ratios from Tab 3
      OAK_rats_to_use <- roll_OAK_tab3()
      return(OAK_rats_to_use)
    } else {stop("Please calculate on Tab 3 first")}
  # Else if user wants to upload their own ratios...  
  } else if (input$OAK_rats == "Upload my own previously computed ratios"){
    # Read in uploaded ratios
    OAK_rats_to_use <- utils::read.csv(input$user_uploaded_OAK$datapath)
    return(OAK_rats_to_use)
  }
})

# Check selected dust metals data input
inspect_dust <- reactive({
  
  # Check data for formatting
  result <- check_processed_dust(data = dust_rats_tab4())
  
})

# Render results of the inspection
output$inspection_results_dust <- renderText({
  # Require a data input to be selected
  shiny::validate(
    need(dust_rats_tab4(), "Result will be shown here after dust ratios data input is selected:")
  )
  
  # Perform inspection
  inspect_dust()
}) %>% 
  bindEvent(input$submit_button_tab4)

# Check selected biomass burning OA/K data input
inspect_OAK <- reactive({
  
  # Check data for formatting
  result <- check_processed_OAK(data = OAK_rats_tab4())
           
})

# Render results of the inspection
output$inspection_results_OAK <- renderText({
  # Require a data input to be selected
  shiny::validate(
    need(OAK_rats_tab4(), "Result will be shown here after OA/K ratios data input is selected:")
  )
  
  # Perform inspection
  inspect_OAK()
}) %>% 
  bindEvent(input$submit_button_tab4)

# Filter dust metals to prep for processing
prep_dust_tab4 <- reactive({
  # If inspection is successful...
  if (inspect_dust() == "Success! Your data is formatted properly."){
    
    bkgd_rats <- dust_rats_tab4() |>
      group_by(Metal) |>
      filter(slope_odr > quantile(slope_odr, probs = 0.05) & slope_odr < quantile(slope_odr,probs = 0.95))
    
    return(bkgd_rats)}
  
})

# Filter OA/K to prep for processing
prep_OAK_tab4 <- reactive({
  # If inspection is successful...
  if (inspect_OAK() == "Success! Your data is formatted properly."){
    
    # group into seasonal distributions and remove extremes
    OA_K_rats_all <- OAK_rats_tab4() |>
      mutate(month = month(start_datetime)) |>
      mutate(season = case_when(month %in% c(12,1,2,3) ~ "DJFM",
                                month %in% c(4,5) ~ "AM",
                                month %in% c(6,7,8,9) ~ "JJAS",
                                month %in% c(10,11) ~ "ON")) |>
      group_by(season) |>
      filter((slope_odr > quantile(slope_odr,na.rm=TRUE,probs = 0.05)) & (slope_odr < quantile(slope_odr,na.rm=TRUE,probs = 0.95)))
    
    return(OA_K_rats_all)
  }
})

# Prep the CSV from Tab 1 for further computation
prep_fullsite_tab4 <- reactive({
  # Return nothing if no file is uploaded
  if (is.null(input$file0)) {
    return(NULL)
  }
  
  # If inspection passes, read in uploaded file
  if (inspect_file() == "Success! Your data is formatted properly."){
    fullsite <- utils::read.csv(input$file0$datapath)
    
    # Comment this out because we're not using local_time anymore
    # for (i in 1:nrow(fullsite)){
    #   # Format value_datetime column according to the time zone and selected timestamp
    #   fullsite$value_datetime[i] <- as.character(as.POSIXct(fullsite$value_datetime[i], tz = fullsite$timezone[i], format = input$timestamp_string))
    #   fullsite$local_time[i] <- as.character(with_tz(fullsite$value_datetime[i], tzone = "America/New_York"))
    #   }
    # 
    
    # Create an empty list to hold results
    df_list <- list()
    # For each unique timezone...
    for (a_timezone in unique(fullsite$timezone)){
      sub_df <- fullsite %>%
        # Filter to the rows with that timezone
        filter(timezone == a_timezone) %>%
        # Format value_datetime column according to the time zone and selected timestamp
        mutate(value_datetime = as.character(as.POSIXct(value_datetime, tz = a_timezone, format = input$timestamp_string))) 
      
      # Save result
      df_list[[a_timezone]] <- sub_df
    }
    
    fullsite <- df_list %>%
      # Combine results altogether
      purrr::list_rbind(x = .)
    
    return(fullsite)
  } else {
    stop("CSV not formatted correctly; please check error message on Tab 1")
  }
})

# Remove points due to fireworks
prep_fireworks_tab4 <- reactive({
  # remove points likely influenced by fireworks, they shouldn't be considered in analysis as computation of BBOA is too uncertain
  fullsite <- remove_fireworks(prep_fullsite_tab4(), firework_metal = "value_Sr", firework_threshold = input$firework_cutoff)
  
  # add the same seasonal groups to the fullsite data frame
  fullsite <- fullsite |> 
    mutate(month = month(value_datetime)) |>
    mutate(season = case_when(month %in% c(12,1,2,3) ~ "DJFM",
                              month %in% c(4,5) ~ "AM",
                              month %in% c(6,7,8,9) ~ "JJAS",
                              month %in% c(10,11) ~ "ON")) 
  
  return(fullsite)
})

# Estimate biomass burning OA via Monte Carlo approach
bboa_tab4 <- reactive({
  # If user selected "No" for season-specific ratios...
  if (input$season_specific2 == "No"){
    ## all seasons
    OA_K_rats <- prep_OAK_tab4()$slope_odr
    
    dust_ts <- prep_fireworks_tab4() |>
      select(value_Fe,value_Ca,value_Ti)
    
    all_seasons <- monte_carlo_simulation(dust_rat_df = prep_dust_tab4(),
                                          seaspray_rat_df = seaspray_rats,
                                          OA_K_rat_array = OA_K_rats,
                                          dust_conc_df = dust_ts,
                                          K_array = prep_fireworks_tab4()$value_K,
                                          Cl_array = prep_fireworks_tab4()$value_Cl,
                                          ts_array = prep_fireworks_tab4()$value_datetime,
                                          tz_array = prep_fireworks_tab4()$timezone,
                                          n_simulations = input$n_iterations)
    
    all_seasons <- all_seasons[[1]]
    
    all_seasons <- all_seasons |>
      arrange(value_datetime) |>
      left_join(prep_fireworks_tab4(), by = c("value_datetime", "timezone")) |>
      mutate(frac_OA_pred = TBBOA_mean/value_OA) |>
      mutate(TBBOA_mean = if_else(TBBOA_mean < 0,0,TBBOA_mean)) |>
      mutate(TBBOA_5pct = if_else(TBBOA_5pct < 0,0,TBBOA_5pct)) |>
      mutate(TBBOA_95pct = if_else(TBBOA_95pct < 0,0,TBBOA_95pct)) |>
      mutate(frac_OA_pred = if_else(frac_OA_pred <0,0,frac_OA_pred))
    
    return(all_seasons)
    
  # If user selected "Yes" for season-specific ratios...
  } else if (input$season_specific2 == "Yes"){
    
    ## winter
    OA_K_rats <- prep_OAK_tab4() |>
      filter(season == "DJFM")
    OA_K_rats <- OA_K_rats$slope_odr
    
    fullsite_filt <- prep_fireworks_tab4() |>
      filter(season == "DJFM") 
    
    dust_ts <- fullsite_filt |>
      select(value_Fe,value_Ca,value_Ti) # time series of dust metals to be used in calculating Kdust/Kbb
    
    TBBOA_winter <- monte_carlo_simulation(dust_rat_df = prep_dust_tab4(),
                                           seaspray_rat_df = seaspray_rats,
                                           OA_K_rat_array = OA_K_rats,
                                           dust_conc_df = dust_ts,
                                           K_array = fullsite_filt$value_K,
                                           Cl_array = fullsite_filt$value_Cl,
                                           ts_array = fullsite_filt$value_datetime,
                                           tz_array = fullsite_filt$timezone,
                                           n_simulations = input$n_iterations)
    TBBOA_winter <- TBBOA_winter[[1]]
    
    ## spring
    OA_K_rats <- prep_OAK_tab4() |>
      filter(season == "AM")
    OA_K_rats <- OA_K_rats$slope_odr
    
    fullsite_filt <- prep_fireworks_tab4() |>
      filter(season == "AM") 
    
    dust_ts <- fullsite_filt |>
      select(value_Fe,value_Ca,value_Ti) # time series of dust metals to be used in calculating Kdust/Kbb
    
    TBBOA_spring <- monte_carlo_simulation(dust_rat_df = prep_dust_tab4(),
                                           seaspray_rat_df = seaspray_rats,
                                           OA_K_rat_array = OA_K_rats,
                                           dust_conc_df = dust_ts,
                                           K_array = fullsite_filt$value_K,
                                           Cl_array = fullsite_filt$value_Cl,
                                           ts_array = fullsite_filt$value_datetime,
                                           tz_array = fullsite_filt$timezone,
                                           n_simulations = input$n_iterations)
    TBBOA_spring <- TBBOA_spring[[1]]
    
    ## summer
    OA_K_rats <- prep_OAK_tab4() |>
      filter(season == "JJAS")
    OA_K_rats <- OA_K_rats$slope_odr
    
    fullsite_filt <- prep_fireworks_tab4() |>
      filter(season == "JJAS") 
    
    dust_ts <- fullsite_filt |>
      select(value_Fe,value_Ca,value_Ti) # time series of dust metals to be used in calculating Kdust/Kbb
    
    TBBOA_summer <- monte_carlo_simulation(dust_rat_df = prep_dust_tab4(),
                                           seaspray_rat_df = seaspray_rats,
                                           OA_K_rat_array = OA_K_rats,
                                           dust_conc_df = dust_ts,
                                           K_array = fullsite_filt$value_K,
                                           Cl_array = fullsite_filt$value_Cl,
                                           ts_array = fullsite_filt$value_datetime,
                                           tz_array = fullsite_filt$timezone,
                                           n_simulations = input$n_iterations)
    TBBOA_summer <- TBBOA_summer[[1]]
    
    
    ## fall
    OA_K_rats <- prep_OAK_tab4() |>
      filter(season == "ON")
    OA_K_rats <- OA_K_rats$slope_odr
    
    fullsite_filt <- prep_fireworks_tab4() |>
      filter(season == "ON") 
    
    dust_ts <- fullsite_filt |>
      select(value_Fe,value_Ca,value_Ti) # time series of dust metals to be used in calculating Kdust/Kbb
    
    TBBOA_fall <- monte_carlo_simulation(dust_rat_df = prep_dust_tab4(),
                                         seaspray_rat_df = seaspray_rats,
                                         OA_K_rat_array = OA_K_rats,
                                         dust_conc_df = dust_ts,
                                         K_array = fullsite_filt$value_K, 
                                         Cl_array = fullsite_filt$value_Cl,
                                         ts_array = fullsite_filt$value_datetime,
                                         tz_array = fullsite_filt$timezone, 
                                         n_simulations =input$n_iterations)
    TBBOA_fall <- TBBOA_fall[[1]]
    
    ## stitch seasons together
    TBBOA <- rbind(TBBOA_winter,TBBOA_spring, TBBOA_summer, TBBOA_fall)
    
    TBBOA <- TBBOA |>
      arrange(value_datetime) |>
      left_join(prep_fireworks_tab4(), by = c("value_datetime", "timezone")) |>
      mutate(frac_OA_pred = TBBOA_mean/value_OA) |>
      mutate(TBBOA_mean = if_else(TBBOA_mean < 0,0,TBBOA_mean)) |>
      mutate(TBBOA_5pct = if_else(TBBOA_5pct < 0,0,TBBOA_5pct)) |>
      mutate(TBBOA_95pct = if_else(TBBOA_95pct < 0,0,TBBOA_95pct)) |>
      mutate(frac_OA_pred = if_else(frac_OA_pred <0,0,frac_OA_pred))
    
    return(TBBOA)
  }
  
})

# Render model parameter inputs as text
output$model_params_tab4 <- renderText({
  shiny::validate(
    need(input$file0, "Name of uploaded file will be shown here after you upload a file and click 'Submit':")
  )
  
  # Don't proceed if any input is invalid
  req(iv3$is_valid())
  
  paste0("Your current file: ", input$file0$name, 
        "\nFireworks cutoff: ", input$firework_cutoff,
        "\nMonte Carlo iterations: ", input$n_iterations,
        "\nDust ratios data input: ", input$dust_rats,
        "\nOA/K ratios data input: ", input$OAK_rats,
        "\nSeason-specific ratio distributions: ", input$season_specific2)
}) %>% 
  bindEvent(input$submit_button_tab4)

# Render BBOA table
output$bboa_table_tab4 <- renderTable({
  shiny::validate(
    need(input$file0, "Results will be shown here after you upload a file on Tab 1 and click 'Submit':"),
    need(dust_rats_tab4(), "Result will be shown here after dust ratios data input is selected:"),
    need(OAK_rats_tab4(), "Result will be shown here after OA/K ratios data input is selected:"))
  
  # Don't proceed if any input is invalid
  req(iv3$is_valid())
  
  # Create the BBOA table when the Submit button is clicked
  bboa_tab4()[1:100,]}, digits = 3) %>% 
  bindEvent(input$submit_button_tab4)

# BBOA table download button
output$dl_tab4 <- downloadHandler(
  # Create the output file name
  filename = function(){
    paste0("custom_table_", Sys.Date(), ".csv")
  },
  # Save BBOA table as CSV
  content = function(file) {
    readr::write_csv(bboa_tab4(), file)
    
  }
)
```